{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GuP_JUdbUvYV"
      },
      "source": [
        "Cấu trúc file để chạy (mục Folder Mistral Github)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oyst7JI5Uljh"
      },
      "source": [
        "![Screenshot 2025-05-30 105305.png](data:image/png;base64,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)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bZKbeIokprH-",
        "outputId": "81537f89-572a-4613-893e-9502e0ff908b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: overrides in /usr/local/lib/python3.11/dist-packages (7.7.0)\n"
          ]
        }
      ],
      "source": [
        "pip install overrides"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XBIrVoy2DXAk",
        "outputId": "950d14d5-6fec-4e34-fff0-c714ad2fdb66"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: streamlit in /usr/local/lib/python3.11/dist-packages (1.45.1)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.2.1)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.0.2)\n",
            "Requirement already satisfied: packaging<25,>=20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (24.2)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.2.2)\n",
            "Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (11.2.1)\n",
            "Requirement already satisfied: protobuf<7,>=3.20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.29.5)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (18.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.32.3)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (9.1.2)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (4.13.2)\n",
            "Requirement already satisfied: watchdog<7,>=2.1.5 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.0.0)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.11/dist-packages (from streamlit) (3.1.44)\n",
            "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.9.1)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (3.1.6)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (4.24.0)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (1.41.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2025.4.26)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (3.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.25.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n",
            "\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K⠇\u001b[1G\u001b[0K⠏\u001b[1G\u001b[0K⠋\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K\n",
            "changed 22 packages in 2s\n",
            "\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K\n",
            "\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K3 packages are looking for funding\n",
            "\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K  run `npm fund` for details\n",
            "\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K"
          ]
        }
      ],
      "source": [
        "!pip install streamlit\n",
        "!npm install -g localtunnel\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-LWMkqS2HdQt",
        "outputId": "d056bd55-5c4e-4b0f-f9c3-de0cbaa6592e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "34.145.7.215"
          ]
        }
      ],
      "source": [
        "!curl https://loca.lt/mytunnelpassword"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GqeSwl5dUVLM"
      },
      "source": [
        "Nhập mk vào link"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rByAm3bNRb0j",
        "outputId": "d035a08b-4cfd-4b1e-ab90-47fe49f251f1"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K⠇\u001b[1G\u001b[0K⠏\u001b[1G\u001b[0K⠋\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K⠇\u001b[1G\u001b[0K⠏\u001b[1G\u001b[0K⠋\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K⠇\u001b[1G\u001b[0K⠏\u001b[1G\u001b[0K⠋\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K⠇\u001b[1G\u001b[0K⠏\u001b[1G\u001b[0K⠋\u001b[1G\u001b[0K\n",
            "changed 44 packages in 4s\n",
            "\u001b[1G\u001b[0K⠋\u001b[1G\u001b[0K\n",
            "\u001b[1G\u001b[0K⠋\u001b[1G\u001b[0K9 packages are looking for funding\n",
            "\u001b[1G\u001b[0K⠋\u001b[1G\u001b[0K  run `npm fund` for details\n",
            "\u001b[1G\u001b[0K⠋\u001b[1G\u001b[0K"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q streamlit cloudflared"
      ],
      "metadata": {
        "id": "CMoaXlQgRjNC"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Chạy Streamlit ngầm + Cloudflared\n",
        "import threading\n",
        "import time\n",
        "import os\n",
        "\n",
        "def run_streamlit():\n",
        "    os.system('streamlit run Demo.py --server.port 8502')\n",
        "\n",
        "def run_cloudflared():\n",
        "    time.sleep(5)\n",
        "    os.system('cloudflared tunnel --url http://localhost:8502')\n",
        "\n",
        "threading.Thread(target=run_streamlit).start()\n",
        "threading.Thread(target=run_cloudflared).start()\n"
      ],
      "metadata": {
        "id": "h05NecDgScPO"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import subprocess\n",
        "import threading\n",
        "import time\n",
        "\n",
        "def run_streamlit():\n",
        "    subprocess.Popen([\"streamlit\", \"run\", \"Demo.py\", \"--server.port\", \"8502\"])\n",
        "\n",
        "def run_cloudflared():\n",
        "    time.sleep(5)\n",
        "    print(\"⏳ Đang khởi tạo đường hầm Cloudflared...\")\n",
        "    output = subprocess.check_output([\"cloudflared\", \"tunnel\", \"--url\", \"http://localhost:8502\", \"--no-autoupdate\"], stderr=subprocess.STDOUT)\n",
        "    print(\"✅ Link public của bạn:\")\n",
        "    for line in output.decode().split(\"\\n\"):\n",
        "        if \"trycloudflare.com\" in line:\n",
        "            print(\"🔗\", line.strip())\n",
        "\n",
        "threading.Thread(target=run_streamlit).start()\n",
        "threading.Thread(target=run_cloudflared).start()\n"
      ],
      "metadata": {
        "id": "_m5qa10-Sr1p"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -q https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64 -O cloudflared\n",
        "!chmod +x cloudflared\n",
        "!mv cloudflared /usr/local/bin/\n"
      ],
      "metadata": {
        "id": "nL9GiXIeSyf2"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!which cloudflared\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3m-Gr0QGS6ag",
        "outputId": "3129ebb1-f941-40a1-c5bd-048e83b18d27"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/bin/cloudflared\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!streamlit run Demo.py & npx localtunnel --port 8501"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KMfr3QfxbRqS",
        "outputId": "dd89fef2-df7f-4140-f07c-19723ff8b9da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
            "\u001b[0m\n",
            "\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K⠇\u001b[1G\u001b[0K\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://34.145.7.215:8501\u001b[0m\n",
            "\u001b[0m\n",
            "your url is: https://tasty-candles-rest.loca.lt\n",
            "2025-06-05 16:44:09.148817: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1749141849.172388   55282 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1749141849.179610   55282 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-06-05 16:44:09.203983: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Loading checkpoint shards: 100% 2/2 [00:02<00:00,  1.07s/it]\n",
            "2025-06-05 16:44:17.205 Examining the path of torch.classes raised:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/streamlit/web/bootstrap.py\", line 347, in run\n",
            "    if asyncio.get_running_loop().is_running():\n",
            "       ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "RuntimeError: no running event loop\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/streamlit/watcher/local_sources_watcher.py\", line 217, in get_module_paths\n",
            "    potential_paths = extract_paths(module)\n",
            "                      ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/streamlit/watcher/local_sources_watcher.py\", line 210, in <lambda>\n",
            "    lambda m: list(m.__path__._path),\n",
            "                   ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/_classes.py\", line 13, in __getattr__\n",
            "    proxy = torch._C._get_custom_class_python_wrapper(self.name, attr)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "RuntimeError: Tried to instantiate class '__path__._path', but it does not exist! Ensure that it is registered via torch::class_\n",
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[31m──\u001b[0m\u001b[31m────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m─────────────────────────\u001b[0m\u001b[31m──\u001b[0m\n",
            "\u001b[31m \u001b[0m \u001b[2;33m/usr/local/lib/python3.11/dist-packages/streamlit/runtime/scriptrunner/\u001b[0m\u001b[1;33mexec_code.py\u001b[0m: \u001b[31m \u001b[0m\n",
            "\u001b[31m \u001b[0m \u001b[94m121\u001b[0m in \u001b[92mexec_func_with_error_handling\u001b[0m                                                 \u001b[31m \u001b[0m\n",
            "\u001b[31m \u001b[0m                                                                                      \u001b[31m \u001b[0m\n",
            "\u001b[31m \u001b[0m \u001b[2;33m/usr/local/lib/python3.11/dist-packages/streamlit/runtime/scriptrunner/\u001b[0m\u001b[1;33mscript_runner\u001b[0m \u001b[31m \u001b[0m\n",
            "\u001b[31m \u001b[0m \u001b[1;33m.py\u001b[0m:\u001b[94m645\u001b[0m in \u001b[92mcode_to_exec\u001b[0m                                                              \u001b[31m \u001b[0m\n",
            "\u001b[31m \u001b[0m                                                                                      \u001b[31m \u001b[0m\n",
            "\u001b[31m \u001b[0m \u001b[2;33m/content/\u001b[0m\u001b[1;33mDemo.py\u001b[0m:\u001b[94m6\u001b[0m in \u001b[92m<module>\u001b[0m                                                       \u001b[31m \u001b[0m\n",
            "\u001b[31m \u001b[0m                                                                                      \u001b[31m \u001b[0m\n",
            "\u001b[31m \u001b[0m   \u001b[2m 3 \u001b[0m\u001b[94mimport\u001b[0m\u001b[90m \u001b[0m\u001b[4;96mgc\u001b[0m                                                                       \u001b[31m \u001b[0m\n",
            "\u001b[31m \u001b[0m   \u001b[2m 4 \u001b[0m\u001b[94mimport\u001b[0m\u001b[90m \u001b[0m\u001b[4;96mos\u001b[0m                                                                       \u001b[31m \u001b[0m\n",
            "\u001b[31m \u001b[0m   \u001b[2m 5 \u001b[0m\u001b[94mfrom\u001b[0m\u001b[90m \u001b[0m\u001b[4;96mtransformers\u001b[0m\u001b[90m \u001b[0m\u001b[94mimport\u001b[0m AutoTokenizer, AutoModelForCausalLM                    \u001b[31m \u001b[0m\n",
            "\u001b[31m \u001b[0m \u001b[31m❱ \u001b[0m 6 \u001b[1;4;94mfrom\u001b[0m\u001b[1;4;90m \u001b[0m\u001b[1;4;96mMain\u001b[0m\u001b[1;4;90m \u001b[0m\u001b[1;4;94mimport\u001b[0m\u001b[1;4m Main\u001b[0m                                                           \u001b[31m \u001b[0m\n",
            "\u001b[31m \u001b[0m   \u001b[2m 7 \u001b[0m                                                                                \u001b[31m \u001b[0m\n",
            "\u001b[31m \u001b[0m   \u001b[2m 8 \u001b[0mgc.collect()                                                                    \u001b[31m \u001b[0m\n",
            "\u001b[31m \u001b[0m   \u001b[2m 9 \u001b[0mtorch.cuda.empty_cache()                                                        \u001b[31m \u001b[0m\n",
            "\u001b[31m \u001b[0m in \u001b[92m_find_and_load\u001b[0m:\u001b[94m1176\u001b[0m                                                               \u001b[31m \u001b[0m\n",
            "\u001b[31m \u001b[0m in \u001b[92m_find_and_load_unlocked\u001b[0m:\u001b[94m1147\u001b[0m                                                      \u001b[31m \u001b[0m\n",
            "\u001b[31m \u001b[0m in \u001b[92m_load_unlocked\u001b[0m:\u001b[94m701\u001b[0m                                                                \u001b[31m \u001b[0m\n",
            "\u001b[31m────────────────────────────────────────────────────────────────────────────────────────\u001b[0m\n",
            "\u001b[1;91mKeyError: \u001b[0m\u001b[32m'Main'\u001b[0m\n",
            "2025-06-05 16:49:35.841 Examining the path of torch.classes raised:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/streamlit/web/bootstrap.py\", line 347, in run\n",
            "    if asyncio.get_running_loop().is_running():\n",
            "       ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "RuntimeError: no running event loop\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/streamlit/watcher/local_sources_watcher.py\", line 217, in get_module_paths\n",
            "    potential_paths = extract_paths(module)\n",
            "                      ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/streamlit/watcher/local_sources_watcher.py\", line 210, in <lambda>\n",
            "    lambda m: list(m.__path__._path),\n",
            "                   ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/_classes.py\", line 13, in __getattr__\n",
            "    proxy = torch._C._get_custom_class_python_wrapper(self.name, attr)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "RuntimeError: Tried to instantiate class '__path__._path', but it does not exist! Ensure that it is registered via torch::class_\n",
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[31m──\u001b[0m\u001b[31m────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m─────────────────────────\u001b[0m\u001b[31m──\u001b[0m\n",
            "\u001b[31m \u001b[0m \u001b[2;33m/usr/local/lib/python3.11/dist-packages/streamlit/runtime/scriptrunner/\u001b[0m\u001b[1;33mexec_code.py\u001b[0m: \u001b[31m \u001b[0m\n",
            "\u001b[31m \u001b[0m \u001b[94m121\u001b[0m in \u001b[92mexec_func_with_error_handling\u001b[0m                                                 \u001b[31m \u001b[0m\n",
            "\u001b[31m \u001b[0m                                                                                      \u001b[31m \u001b[0m\n",
            "\u001b[31m \u001b[0m \u001b[2;33m/usr/local/lib/python3.11/dist-packages/streamlit/runtime/scriptrunner/\u001b[0m\u001b[1;33mscript_runner\u001b[0m \u001b[31m \u001b[0m\n",
            "\u001b[31m \u001b[0m \u001b[1;33m.py\u001b[0m:\u001b[94m645\u001b[0m in \u001b[92mcode_to_exec\u001b[0m                                                              \u001b[31m \u001b[0m\n",
            "\u001b[31m \u001b[0m                                                                                      \u001b[31m \u001b[0m\n",
            "\u001b[31m \u001b[0m \u001b[2;33m/content/\u001b[0m\u001b[1;33mDemo.py\u001b[0m:\u001b[94m6\u001b[0m in \u001b[92m<module>\u001b[0m                                                       \u001b[31m \u001b[0m\n",
            "\u001b[31m \u001b[0m                                                                                      \u001b[31m \u001b[0m\n",
            "\u001b[31m \u001b[0m   \u001b[2m 3 \u001b[0m\u001b[94mimport\u001b[0m\u001b[90m \u001b[0m\u001b[4;96mgc\u001b[0m                                                                       \u001b[31m \u001b[0m\n",
            "\u001b[31m \u001b[0m   \u001b[2m 4 \u001b[0m\u001b[94mimport\u001b[0m\u001b[90m \u001b[0m\u001b[4;96mos\u001b[0m                                                                       \u001b[31m \u001b[0m\n",
            "\u001b[31m \u001b[0m   \u001b[2m 5 \u001b[0m\u001b[94mfrom\u001b[0m\u001b[90m \u001b[0m\u001b[4;96mtransformers\u001b[0m\u001b[90m \u001b[0m\u001b[94mimport\u001b[0m AutoTokenizer, AutoModelForCausalLM                    \u001b[31m \u001b[0m\n",
            "\u001b[31m \u001b[0m \u001b[31m❱ \u001b[0m 6 \u001b[1;4;94mfrom\u001b[0m\u001b[1;4;90m \u001b[0m\u001b[1;4;96mMain\u001b[0m\u001b[1;4;90m \u001b[0m\u001b[1;4;94mimport\u001b[0m\u001b[1;4m Main\u001b[0m                                                           \u001b[31m \u001b[0m\n",
            "\u001b[31m \u001b[0m   \u001b[2m 7 \u001b[0m                                                                                \u001b[31m \u001b[0m\n",
            "\u001b[31m \u001b[0m   \u001b[2m 8 \u001b[0mgc.collect()                                                                    \u001b[31m \u001b[0m\n",
            "\u001b[31m \u001b[0m   \u001b[2m 9 \u001b[0mtorch.cuda.empty_cache()                                                        \u001b[31m \u001b[0m\n",
            "\u001b[31m \u001b[0m                                                                                      \u001b[31m \u001b[0m\n",
            "\u001b[31m \u001b[0m \u001b[2;33m/content/\u001b[0m\u001b[1;33mMain.py\u001b[0m:\u001b[94m1\u001b[0m in \u001b[92m<module>\u001b[0m                                                       \u001b[31m \u001b[0m\n",
            "\u001b[31m \u001b[0m                                                                                      \u001b[31m \u001b[0m\n",
            "\u001b[31m \u001b[0m \u001b[31m❱ \u001b[0m 1 \u001b[1;4;94mfrom\u001b[0m\u001b[1;4;90m \u001b[0m\u001b[1;4;96mbasic_prompt_designs\u001b[0m\u001b[1;4;96m.\u001b[0m\u001b[1;4;96mClassfication\u001b[0m\u001b[1;4;90m \u001b[0m\u001b[1;4;94mimport\u001b[0m\u001b[1;4m Classification\u001b[0m                   \u001b[31m \u001b[0m\n",
            "\u001b[31m \u001b[0m   \u001b[2m 2 \u001b[0m\u001b[94mfrom\u001b[0m\u001b[90m \u001b[0m\u001b[4;96mbasic_prompt_designs\u001b[0m\u001b[4;96m.\u001b[0m\u001b[4;96mComputation\u001b[0m\u001b[90m \u001b[0m\u001b[94mimport\u001b[0m Computation                        \u001b[31m \u001b[0m\n",
            "\u001b[31m \u001b[0m   \u001b[2m 3 \u001b[0m\u001b[94mfrom\u001b[0m\u001b[90m \u001b[0m\u001b[4;96mbasic_prompt_designs\u001b[0m\u001b[4;96m.\u001b[0m\u001b[4;96mQA_knowledge\u001b[0m\u001b[90m \u001b[0m\u001b[94mimport\u001b[0m QA_knowledge                      \u001b[31m \u001b[0m\n",
            "\u001b[31m \u001b[0m   \u001b[2m 4 \u001b[0m\u001b[94mfrom\u001b[0m\u001b[90m \u001b[0m\u001b[4;96mbasic_prompt_designs\u001b[0m\u001b[4;96m.\u001b[0m\u001b[4;96mReasoning\u001b[0m\u001b[90m \u001b[0m\u001b[94mimport\u001b[0m Reasoning                            \u001b[31m \u001b[0m\n",
            "\u001b[31m────────────────────────────────────────────────────────────────────────────────────────\u001b[0m\n",
            "\u001b[91m────────────────────────────────────────────────────────────────────────────────────────\u001b[0m\n",
            "\u001b[91m \u001b[0m \u001b[2;33m /content/basic_prompt_designs/\u001b[0m\u001b[1;33mClassfication.py\u001b[0m\u001b[1m:\u001b[0m\u001b[1;94m185\u001b[0m                                  \u001b[91m \u001b[0m\n",
            "\u001b[91m \u001b[0m         max_len =                                                                    \u001b[91m \u001b[0m\n",
            "\u001b[91m \u001b[0m                  \u001b[1;91m▲\u001b[0m                                                                   \u001b[91m \u001b[0m\n",
            "\u001b[91m────────────────────────────────────────────────────────────────────────────────────────\u001b[0m\n",
            "\u001b[1;91mSyntaxError: \u001b[0minvalid syntax\n",
            "2025-06-05 16:51:32.601 Examining the path of torch.classes raised:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/streamlit/web/bootstrap.py\", line 347, in run\n",
            "    if asyncio.get_running_loop().is_running():\n",
            "       ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "RuntimeError: no running event loop\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/streamlit/watcher/local_sources_watcher.py\", line 217, in get_module_paths\n",
            "    potential_paths = extract_paths(module)\n",
            "                      ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/streamlit/watcher/local_sources_watcher.py\", line 210, in <lambda>\n",
            "    lambda m: list(m.__path__._path),\n",
            "                   ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/_classes.py\", line 13, in __getattr__\n",
            "    proxy = torch._C._get_custom_class_python_wrapper(self.name, attr)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "RuntimeError: Tried to instantiate class '__path__._path', but it does not exist! Ensure that it is registered via torch::class_\n",
            "2025-06-05 16:51:52.668 Examining the path of torch.classes raised:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/streamlit/web/bootstrap.py\", line 347, in run\n",
            "    if asyncio.get_running_loop().is_running():\n",
            "       ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "RuntimeError: no running event loop\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/streamlit/watcher/local_sources_watcher.py\", line 217, in get_module_paths\n",
            "    potential_paths = extract_paths(module)\n",
            "                      ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/streamlit/watcher/local_sources_watcher.py\", line 210, in <lambda>\n",
            "    lambda m: list(m.__path__._path),\n",
            "                   ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/_classes.py\", line 13, in __getattr__\n",
            "    proxy = torch._C._get_custom_class_python_wrapper(self.name, attr)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "RuntimeError: Tried to instantiate class '__path__._path', but it does not exist! Ensure that it is registered via torch::class_\n",
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\n",
            "                You are a reasoning assistant. Read the question and answer by thinking step by step before giving a final answer.\n",
            "                Q: A man walks into a room and sees a broken window and a baseball lying on the floor. What probably happened?\n",
            "                Let's think step by step. A window is broken and a baseball is inside the room. A baseball could break a window. It was likely hit from outside. \n",
            "                \n",
            "                A: Someone accidentally hit the ball through the window.\n",
            "                Q: A woman hears the fire alarm and smells smoke coming from the kitchen. What should she do?\n",
            "                Let's think step by step. The fire alarm suggests a possible fire. Smoke from the kitchen reinforces that. Safety is important. \n",
            "                \n",
            "                A: She should quickly check the kitchen and call emergency services if there's a fire.\n",
            "                Q: A student studied hard for an exam and felt confident after taking it. What is the likely outcome?\n",
            "                Let's think step by step. Studying hard usually improves performance. Confidence after the exam suggests it went well.\n",
            "                \n",
            "                A: The student probably performed well on the exam.\n",
            "                Q: khi một dòng nước chảy ở 1 nơi hoang vắng thì trường hợp nào dễ xảy ra nhất A.nơi đó có người sống B.nơi đó nguy hiểm \n",
            "                Let's think step by step.\n",
            "                A:\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[31m──\u001b[0m\u001b[31m────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m─────────────────────────\u001b[0m\u001b[31m──\u001b[0m\n",
            "\u001b[31m \u001b[0m \u001b[2;33m/usr/local/lib/python3.11/dist-packages/streamlit/runtime/scriptrunner/\u001b[0m\u001b[1;33mexec_code.py\u001b[0m: \u001b[31m \u001b[0m\n",
            "\u001b[31m \u001b[0m \u001b[94m121\u001b[0m in \u001b[92mexec_func_with_error_handling\u001b[0m                                                 \u001b[31m \u001b[0m\n",
            "\u001b[31m \u001b[0m                                                                                      \u001b[31m \u001b[0m\n",
            "\u001b[31m \u001b[0m \u001b[2;33m/usr/local/lib/python3.11/dist-packages/streamlit/runtime/scriptrunner/\u001b[0m\u001b[1;33mscript_runner\u001b[0m \u001b[31m \u001b[0m\n",
            "\u001b[31m \u001b[0m \u001b[1;33m.py\u001b[0m:\u001b[94m645\u001b[0m in \u001b[92mcode_to_exec\u001b[0m                                                              \u001b[31m \u001b[0m\n",
            "\u001b[31m \u001b[0m                                                                                      \u001b[31m \u001b[0m\n",
            "\u001b[31m \u001b[0m \u001b[2;33m/content/\u001b[0m\u001b[1;33mDemo.py\u001b[0m:\u001b[94m6\u001b[0m in \u001b[92m<module>\u001b[0m                                                       \u001b[31m \u001b[0m\n",
            "\u001b[31m \u001b[0m                                                                                      \u001b[31m \u001b[0m\n",
            "\u001b[31m \u001b[0m   \u001b[2m 3 \u001b[0m\u001b[94mimport\u001b[0m\u001b[90m \u001b[0m\u001b[4;96mgc\u001b[0m                                                                       \u001b[31m \u001b[0m\n",
            "\u001b[31m \u001b[0m   \u001b[2m 4 \u001b[0m\u001b[94mimport\u001b[0m\u001b[90m \u001b[0m\u001b[4;96mos\u001b[0m                                                                       \u001b[31m \u001b[0m\n",
            "\u001b[31m \u001b[0m   \u001b[2m 5 \u001b[0m\u001b[94mfrom\u001b[0m\u001b[90m \u001b[0m\u001b[4;96mtransformers\u001b[0m\u001b[90m \u001b[0m\u001b[94mimport\u001b[0m AutoTokenizer, AutoModelForCausalLM                    \u001b[31m \u001b[0m\n",
            "\u001b[31m \u001b[0m \u001b[31m❱ \u001b[0m 6 \u001b[1;4;94mfrom\u001b[0m\u001b[1;4;90m \u001b[0m\u001b[1;4;96mMain\u001b[0m\u001b[1;4;90m \u001b[0m\u001b[1;4;94mimport\u001b[0m\u001b[1;4m Main\u001b[0m                                                           \u001b[31m \u001b[0m\n",
            "\u001b[31m \u001b[0m   \u001b[2m 7 \u001b[0m                                                                                \u001b[31m \u001b[0m\n",
            "\u001b[31m \u001b[0m   \u001b[2m 8 \u001b[0mgc.collect()                                                                    \u001b[31m \u001b[0m\n",
            "\u001b[31m \u001b[0m   \u001b[2m 9 \u001b[0mtorch.cuda.empty_cache()                                                        \u001b[31m \u001b[0m\n",
            "\u001b[31m \u001b[0m                                                                                      \u001b[31m \u001b[0m\n",
            "\u001b[31m \u001b[0m \u001b[2;33m/content/\u001b[0m\u001b[1;33mMain.py\u001b[0m:\u001b[94m1\u001b[0m in \u001b[92m<module>\u001b[0m                                                       \u001b[31m \u001b[0m\n",
            "\u001b[31m \u001b[0m                                                                                      \u001b[31m \u001b[0m\n",
            "\u001b[31m \u001b[0m \u001b[31m❱ \u001b[0m 1 \u001b[1;4;94mfrom\u001b[0m\u001b[1;4;90m \u001b[0m\u001b[1;4;96mbasic_prompt_designs\u001b[0m\u001b[1;4;96m.\u001b[0m\u001b[1;4;96mClassfication\u001b[0m\u001b[1;4;90m \u001b[0m\u001b[1;4;94mimport\u001b[0m\u001b[1;4m Classification\u001b[0m                   \u001b[31m \u001b[0m\n",
            "\u001b[31m \u001b[0m   \u001b[2m 2 \u001b[0m\u001b[94mfrom\u001b[0m\u001b[90m \u001b[0m\u001b[4;96mbasic_prompt_designs\u001b[0m\u001b[4;96m.\u001b[0m\u001b[4;96mComputation\u001b[0m\u001b[90m \u001b[0m\u001b[94mimport\u001b[0m Computation                        \u001b[31m \u001b[0m\n",
            "\u001b[31m \u001b[0m   \u001b[2m 3 \u001b[0m\u001b[94mfrom\u001b[0m\u001b[90m \u001b[0m\u001b[4;96mbasic_prompt_designs\u001b[0m\u001b[4;96m.\u001b[0m\u001b[4;96mQA_knowledge\u001b[0m\u001b[90m \u001b[0m\u001b[94mimport\u001b[0m QA_knowledge                      \u001b[31m \u001b[0m\n",
            "\u001b[31m \u001b[0m   \u001b[2m 4 \u001b[0m\u001b[94mfrom\u001b[0m\u001b[90m \u001b[0m\u001b[4;96mbasic_prompt_designs\u001b[0m\u001b[4;96m.\u001b[0m\u001b[4;96mReasoning\u001b[0m\u001b[90m \u001b[0m\u001b[94mimport\u001b[0m Reasoning                            \u001b[31m \u001b[0m\n",
            "\u001b[31m \u001b[0m in \u001b[92m_find_and_load\u001b[0m:\u001b[94m1176\u001b[0m                                                               \u001b[31m \u001b[0m\n",
            "\u001b[31m \u001b[0m in \u001b[92m_find_and_load_unlocked\u001b[0m:\u001b[94m1147\u001b[0m                                                      \u001b[31m \u001b[0m\n",
            "\u001b[31m \u001b[0m in \u001b[92m_load_unlocked\u001b[0m:\u001b[94m701\u001b[0m                                                                \u001b[31m \u001b[0m\n",
            "\u001b[31m────────────────────────────────────────────────────────────────────────────────────────\u001b[0m\n",
            "\u001b[1;91mKeyError: \u001b[0m\u001b[32m'basic_prompt_designs.Classfication'\u001b[0m\n",
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Loading checkpoint shards: 100% 2/2 [00:02<00:00,  1.09s/it]\n",
            "2025-06-05 17:05:38.461 Examining the path of torch.classes raised:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/streamlit/web/bootstrap.py\", line 347, in run\n",
            "    if asyncio.get_running_loop().is_running():\n",
            "       ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "RuntimeError: no running event loop\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/streamlit/watcher/local_sources_watcher.py\", line 217, in get_module_paths\n",
            "    potential_paths = extract_paths(module)\n",
            "                      ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/streamlit/watcher/local_sources_watcher.py\", line 210, in <lambda>\n",
            "    lambda m: list(m.__path__._path),\n",
            "                   ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/_classes.py\", line 13, in __getattr__\n",
            "    proxy = torch._C._get_custom_class_python_wrapper(self.name, attr)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "RuntimeError: Tried to instantiate class '__path__._path', but it does not exist! Ensure that it is registered via torch::class_\n",
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "2025-06-05 17:07:39.316 Examining the path of torch.classes raised:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/streamlit/web/bootstrap.py\", line 347, in run\n",
            "    if asyncio.get_running_loop().is_running():\n",
            "       ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "RuntimeError: no running event loop\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/streamlit/watcher/local_sources_watcher.py\", line 217, in get_module_paths\n",
            "    potential_paths = extract_paths(module)\n",
            "                      ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/streamlit/watcher/local_sources_watcher.py\", line 210, in <lambda>\n",
            "    lambda m: list(m.__path__._path),\n",
            "                   ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/_classes.py\", line 13, in __getattr__\n",
            "    proxy = torch._C._get_custom_class_python_wrapper(self.name, attr)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "RuntimeError: Tried to instantiate class '__path__._path', but it does not exist! Ensure that it is registered via torch::class_\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cloudflared tunnel --url http://localhost:8502 --no-autoupdate\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jOMv_L0lSuIR",
        "outputId": "11b6c635-7edd-4b14-d0bf-1f6de8cf2709"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[90m2025-06-05T15:57:52Z\u001b[0m \u001b[32mINF\u001b[0m Thank you for trying Cloudflare Tunnel. Doing so, without a Cloudflare account, is a quick way to experiment and try it out. However, be aware that these account-less Tunnels have no uptime guarantee, are subject to the Cloudflare Online Services Terms of Use (https://www.cloudflare.com/website-terms/), and Cloudflare reserves the right to investigate your use of Tunnels for violations of such terms. If you intend to use Tunnels in production you should use a pre-created named tunnel by following: https://developers.cloudflare.com/cloudflare-one/connections/connect-apps\n",
            "\u001b[90m2025-06-05T15:57:52Z\u001b[0m \u001b[32mINF\u001b[0m Requesting new quick Tunnel on trycloudflare.com...\n",
            "\u001b[90m2025-06-05T15:57:56Z\u001b[0m \u001b[32mINF\u001b[0m +--------------------------------------------------------------------------------------------+\n",
            "\u001b[90m2025-06-05T15:57:56Z\u001b[0m \u001b[32mINF\u001b[0m |  Your quick Tunnel has been created! Visit it at (it may take some time to be reachable):  |\n",
            "\u001b[90m2025-06-05T15:57:56Z\u001b[0m \u001b[32mINF\u001b[0m |  https://beef-outlet-paperbacks-carriers.trycloudflare.com                                 |\n",
            "\u001b[90m2025-06-05T15:57:56Z\u001b[0m \u001b[32mINF\u001b[0m +--------------------------------------------------------------------------------------------+\n",
            "\u001b[90m2025-06-05T15:57:56Z\u001b[0m \u001b[32mINF\u001b[0m Cannot determine default configuration path. No file [config.yml config.yaml] in [~/.cloudflared ~/.cloudflare-warp ~/cloudflare-warp /etc/cloudflared /usr/local/etc/cloudflared]\n",
            "\u001b[90m2025-06-05T15:57:56Z\u001b[0m \u001b[32mINF\u001b[0m Version 2025.5.0 (Checksum a62266fd02041374f1fca0d85694aafdf7e26e171a314467356b471d4ebb2393)\n",
            "\u001b[90m2025-06-05T15:57:56Z\u001b[0m \u001b[32mINF\u001b[0m GOOS: linux, GOVersion: go1.22.10, GoArch: amd64\n",
            "\u001b[90m2025-06-05T15:57:56Z\u001b[0m \u001b[32mINF\u001b[0m Settings: map[ha-connections:1 no-autoupdate:true protocol:quic url:http://localhost:8502]\n",
            "\u001b[90m2025-06-05T15:57:56Z\u001b[0m \u001b[32mINF\u001b[0m cloudflared will not automatically update when run from the shell. To enable auto-updates, run cloudflared as a service: https://developers.cloudflare.com/cloudflare-one/connections/connect-apps/configure-tunnels/local-management/as-a-service/\n",
            "\u001b[90m2025-06-05T15:57:56Z\u001b[0m \u001b[32mINF\u001b[0m Generated Connector ID: 76ca65a6-5b59-4d4d-a7a2-72e99318c5bf\n",
            "\u001b[90m2025-06-05T15:57:56Z\u001b[0m \u001b[32mINF\u001b[0m Initial protocol quic\n",
            "\u001b[90m2025-06-05T15:57:56Z\u001b[0m \u001b[32mINF\u001b[0m ICMP proxy will use 172.28.0.12 as source for IPv4\n",
            "\u001b[90m2025-06-05T15:57:56Z\u001b[0m \u001b[32mINF\u001b[0m ICMP proxy will use :: as source for IPv6\n",
            "\u001b[90m2025-06-05T15:57:56Z\u001b[0m \u001b[32mINF\u001b[0m ICMP proxy will use 172.28.0.12 as source for IPv4\n",
            "\u001b[90m2025-06-05T15:57:56Z\u001b[0m \u001b[32mINF\u001b[0m ICMP proxy will use :: as source for IPv6\n",
            "\u001b[90m2025-06-05T15:57:56Z\u001b[0m \u001b[32mINF\u001b[0m Starting metrics server on 127.0.0.1:20241/metrics\n",
            "\u001b[90m2025-06-05T15:57:56Z\u001b[0m \u001b[32mINF\u001b[0m Tunnel connection curve preferences: [CurveID(4588) CurveID(25497) CurveP256] \u001b[36mconnIndex=\u001b[0m0 \u001b[36mevent=\u001b[0m0 \u001b[36mip=\u001b[0m198.41.192.37\n",
            "2025/06/05 15:57:56 failed to sufficiently increase receive buffer size (was: 208 kiB, wanted: 7168 kiB, got: 416 kiB). See https://github.com/quic-go/quic-go/wiki/UDP-Buffer-Sizes for details.\n",
            "\u001b[90m2025-06-05T15:57:56Z\u001b[0m \u001b[32mINF\u001b[0m Registered tunnel connection \u001b[36mconnIndex=\u001b[0m0 \u001b[36mconnection=\u001b[0m2f1b822e-2882-4fb5-bea2-c64a12c9956c \u001b[36mevent=\u001b[0m0 \u001b[36mip=\u001b[0m198.41.192.37 \u001b[36mlocation=\u001b[0msea01 \u001b[36mprotocol=\u001b[0mquic\n",
            "\u001b[90m2025-06-05T15:58:01Z\u001b[0m \u001b[1m\u001b[31mERR\u001b[0m\u001b[0m  \u001b[31merror=\u001b[0m\u001b[31m\"Unable to reach the origin service. The service may be down or it may not be responding to traffic from cloudflared: dial tcp 127.0.0.1:8502: connect: connection refused\"\u001b[0m \u001b[36mconnIndex=\u001b[0m0 \u001b[36mevent=\u001b[0m1 \u001b[36mingressRule=\u001b[0m0 \u001b[36moriginService=\u001b[0mhttp://localhost:8502\n",
            "\u001b[90m2025-06-05T15:58:01Z\u001b[0m \u001b[1m\u001b[31mERR\u001b[0m\u001b[0m Request failed \u001b[31merror=\u001b[0m\u001b[31m\"Unable to reach the origin service. The service may be down or it may not be responding to traffic from cloudflared: dial tcp 127.0.0.1:8502: connect: connection refused\"\u001b[0m \u001b[36mconnIndex=\u001b[0m0 \u001b[36mdest=\u001b[0mhttps://beef-outlet-paperbacks-carriers.trycloudflare.com/ \u001b[36mevent=\u001b[0m0 \u001b[36mip=\u001b[0m198.41.192.37 \u001b[36mtype=\u001b[0mhttp\n",
            "\u001b[90m2025-06-05T15:58:01Z\u001b[0m \u001b[1m\u001b[31mERR\u001b[0m\u001b[0m  \u001b[31merror=\u001b[0m\u001b[31m\"Unable to reach the origin service. The service may be down or it may not be responding to traffic from cloudflared: dial tcp 127.0.0.1:8502: connect: connection refused\"\u001b[0m \u001b[36mconnIndex=\u001b[0m0 \u001b[36mevent=\u001b[0m1 \u001b[36mingressRule=\u001b[0m0 \u001b[36moriginService=\u001b[0mhttp://localhost:8502\n",
            "\u001b[90m2025-06-05T15:58:01Z\u001b[0m \u001b[1m\u001b[31mERR\u001b[0m\u001b[0m Request failed \u001b[31merror=\u001b[0m\u001b[31m\"Unable to reach the origin service. The service may be down or it may not be responding to traffic from cloudflared: dial tcp 127.0.0.1:8502: connect: connection refused\"\u001b[0m \u001b[36mconnIndex=\u001b[0m0 \u001b[36mdest=\u001b[0mhttps://beef-outlet-paperbacks-carriers.trycloudflare.com/favicon.ico \u001b[36mevent=\u001b[0m0 \u001b[36mip=\u001b[0m198.41.192.37 \u001b[36mtype=\u001b[0mhttp\n",
            "\u001b[90m2025-06-05T15:58:04Z\u001b[0m \u001b[32mINF\u001b[0m Initiating graceful shutdown due to signal interrupt ...\n",
            "\u001b[90m2025-06-05T15:58:04Z\u001b[0m \u001b[1m\u001b[31mERR\u001b[0m\u001b[0m Failed to serve tunnel connection \u001b[31merror=\u001b[0m\u001b[31m\"context canceled\"\u001b[0m \u001b[36mconnIndex=\u001b[0m0 \u001b[36mevent=\u001b[0m0 \u001b[36mip=\u001b[0m198.41.192.37\n",
            "\u001b[90m2025-06-05T15:58:04Z\u001b[0m \u001b[32mINF\u001b[0m Retrying connection in up to 1s \u001b[36mconnIndex=\u001b[0m0 \u001b[36mevent=\u001b[0m0 \u001b[36mip=\u001b[0m198.41.192.37\n",
            "\u001b[90m2025-06-05T15:58:04Z\u001b[0m \u001b[1m\u001b[31mERR\u001b[0m\u001b[0m no more connections active and exiting\n",
            "\u001b[90m2025-06-05T15:58:04Z\u001b[0m \u001b[32mINF\u001b[0m Tunnel server stopped\n",
            "\u001b[90m2025-06-05T15:58:04Z\u001b[0m \u001b[32mINF\u001b[0m Metrics server stopped\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "import torch\n",
        "\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()\n"
      ],
      "metadata": {
        "id": "dlYntkEmW-GJ"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "torch.cuda.ipc_collect()\n"
      ],
      "metadata": {
        "id": "X6f9OdEMU7HZ"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ngrok config add-authtoken 2xnUd2dz6AmCRaWs4T8MY1EWAEX_4oFgeBj4RrE4nMxUDh61W\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sgq942viRrJL",
        "outputId": "cd6d7d19-2268-43a6-d092-7173fd3e6d1a"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZELxAgewCxKt",
        "outputId": "230c0505-f47c-4a06-f9f2-f8e550089727"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
            "\u001b[0m\n",
            "2025-06-05 14:07:24.516 Port 8502 is already in use\n"
          ]
        }
      ],
      "source": [
        "!streamlit run Demo.py --server.port 8502 & ngrok http 8502\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ngrok http 8502\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "tVpj-oIuQpIy",
        "outputId": "34990ccd-866b-4377-a39c-3f37c3420c26"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "invalid syntax (<ipython-input-8-d03653826134>, line 1)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-8-d03653826134>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    ngrok http 8502\u001b[0m\n\u001b[0m          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}